<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>C1 → Analyze Datasets and Train ML Models using AutoML</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
}

.simple-table-header {
	background: rgb(247, 246, 243);
	color: black;
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-opaquegray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="1c1b26f6-fd9f-40c7-b2e6-1cb2ab709bbc" class="page sans"><header><h1 class="page-title">C1 → <strong><strong>Analyze Datasets and Train ML Models using AutoML</strong></strong></h1><table class="properties"><tbody><tr class="property-row property-row-created_time"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesCreatedAt"><path d="M6.98643729,14.0000972 C5.19579566,14.0000972 3.40419152,13.3106896 2.04245843,11.9323606 C-0.681017475,9.21200555 -0.680780251,4.76029539 2.04293482,2.04012507 C4.76664406,-0.68004331 9.22427509,-0.68004331 11.9480135,2.04013479 C13.272481,3.36277455 14,5.1330091 14,6.99552762 C14,8.87640182 13.2721894,10.6285043 11.9480135,11.9509302 C10.5679344,13.3105924 8.77756503,14.0000972 6.98643729,14.0000972 Z M10.2705296,7.00913883 L10.2705296,8.46099754 L10.2705296,8.65543362 L10.076181,8.65543362 L8.6543739,8.65543362 L5.72059514,8.65543362 L5.52619796,8.65543362 L5.52619796,8.46099754 L5.52619796,5.52541044 L5.52619796,3.37946773 L5.52619796,3.18502193 L5.72059514,3.18502193 L7.17253164,3.18502193 L7.36692883,3.18502193 L7.36692883,3.37946773 L7.36692883,6.81467358 L10.076181,6.81467358 L10.2705296,6.81467358 L10.2705296,7.00913883 Z M12.1601539,6.99552762 C12.1601539,5.61697497 11.6190112,4.32597154 10.6393933,3.34769528 C8.63253764,1.34336744 5.35197452,1.34061603 3.34153136,3.33944106 C3.33868273,3.34219247 3.33607716,3.34494388 3.33322852,3.34769528 C1.32397148,5.35459953 1.32372842,8.63641682 3.33322852,10.6433794 C5.34295224,12.6504489 8.62968901,12.6504489 10.6393933,10.6433794 C11.6190112,9.66506426 12.1601539,8.37408027 12.1601539,6.99552762 Z"></path></svg></span>Created</th><td><time>@February 16, 2022 2:27 PM</time></td></tr><tr class="property-row property-row-multi_select"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesMultipleSelect"><path d="M4,3 C4,2.447715 4.447715,2 5,2 L12,2 C12.5523,2 13,2.447716 13,3 C13,3.55228 12.5523,4 12,4 L5,4 C4.447715,4 4,3.55228 4,3 Z M4,7 C4,6.447715 4.447715,6 5,6 L12,6 C12.5523,6 13,6.447716 13,7 C13,7.55228 12.5523,8 12,8 L5,8 C4.447715,8 4,7.55228 4,7 Z M4,11 C4,10.447715 4.447715,10 5,10 L12,10 C12.5523,10 13,10.447716 13,11 C13,11.55228 12.5523,12 12,12 L5,12 C4.447715,12 4,11.55228 4,11 Z M2,4 C1.44771525,4 1,3.55228475 1,3 C1,2.44771525 1.44771525,2 2,2 C2.55228475,2 3,2.44771525 3,3 C3,3.55228475 2.55228475,4 2,4 Z M2,8 C1.44771525,8 1,7.55228475 1,7 C1,6.44771525 1.44771525,6 2,6 C2.55228475,6 3,6.44771525 3,7 C3,7.55228475 2.55228475,8 2,8 Z M2,12 C1.44771525,12 1,11.5522847 1,11 C1,10.4477153 1.44771525,10 2,10 C2.55228475,10 3,10.4477153 3,11 C3,11.5522847 2.55228475,12 2,12 Z"></path></svg></span>Tag</th><td><span class="selected-value select-value-color-orange">Code</span><span class="selected-value select-value-color-pink">Trainning</span></td></tr></tbody></table></header><div class="page-body"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="6c1bcaca-8abc-4e50-886e-98a5066ef7d3"><div style="font-size:1.5em"><span class="icon">⚠️</span></div><div style="width:100%"><strong>First Course of Practical Data Science Specialization </strong></div></figure><p id="e58f56e9-889e-4177-aa19-859eca8198d8" class="">
</p><p id="4e072185-7dac-407e-b172-05d8e6064c6b" class="block-color-orange_background"><strong><mark class="highlight-orange_background">Index</mark></strong></p><nav id="3d952d6f-0d4e-476d-930b-9486f195eaaf" class="block-color-gray table_of_contents"><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#7d55e047-51b0-402d-bcb8-838f8491ac3e">Specialization Link</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#a126b67b-9567-468a-820b-2613d1117832">W1 - <strong>Explore the Use Case and Analyze the Dataset</strong></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#a7836455-4df1-49b7-86d9-e2d6c0f75048">Introduction to Practical Data Science</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#7ee4de08-46f8-4705-b4f9-7889895e397d">Use case and data set</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#2778e549-45df-4356-bed2-f440b53119e5">Working with Data</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#28302fe5-df5d-4acf-a8c1-6729784e18f1">Reading Material</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#566b71fd-c832-4abf-970e-ce0ff4ac5e6a">W2 - Data Bias and Feature Importance</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#7c3e1360-62c7-458b-a020-b3c8f23c371e">Statiscal Bias:</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#cc0d31be-5126-4464-8a8b-3226771aa748">Causes:</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#5a39cd2b-336f-4b3a-80b3-ba89acfe2b71">Measure bias</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#26ef5f4e-5e55-4fe1-9455-b22a5271fd00"><strong>SageMaker Data Wrangler:</strong></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#6f8c2c07-8b9c-42d8-85a6-014bcd252b51"><strong>SageMaker Clarify Processor </strong></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#c58b98ea-5ed4-4360-9fc5-0d48649f4f4a"><strong>SM Data Wrangler vs SM Clarify</strong></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#af4b1edb-2a52-4ff7-b382-9612bf2d3c82">SHAP → shapley additive explanations</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#5c945db4-d9bd-4d34-af95-a6f608259e22">Reading Material</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#9f91eaa2-e253-4ea4-9c39-87f51b5647ab">W3 - Automated Machine Learning (AutoML)</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#7fbbcb76-2037-43af-ad6c-c63472da7960">AutoML Flow</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#5e7dd871-ddd6-4c09-85c6-7f257f9e46e5">Sagemaker Autopilot</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#3b3ddd66-5b93-4807-85a2-1dcaec328e99">SM Autopilot outputs:</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#973db3bf-6806-4abe-b0eb-9c96a4becf73">Model Deploy</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#a5882644-baab-4405-a280-f6b739d8f11c">Reading material:</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#ed038e8e-89a8-4673-8d92-a3b5fe8bc6e4">W<strong>4 - Built-in Algorithms</strong></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#cd8bfade-2443-416f-b3eb-99c557892e72">Reading Material</a></div></nav><h1 id="7d55e047-51b0-402d-bcb8-838f8491ac3e" class="">Specialization Link</h1><p id="e4045d1d-42a9-43e4-867b-da72cef7e3d3" class=""><a href="https://www.deeplearning.ai/program/practical-data-science-specialization/">https://www.deeplearning.ai/program/practical-data-science-specialization/</a></p><p id="61bd1371-b819-4a96-92fe-45443d20829c" class=""><a href="https://www.coursera.org/learn/automl-datasets-ml-models?specialization=practical-data-science">https://www.coursera.org/learn/automl-datasets-ml-models?specialization=practical-data-science</a></p><p id="25c4d047-cf87-4cd4-b2eb-3176bca31b8e" class="">
</p><h2 id="a126b67b-9567-468a-820b-2613d1117832" class="block-color-orange_background">W1 - <strong>Explore the Use Case and Analyze the Dataset</strong></h2><h3 id="a7836455-4df1-49b7-86d9-e2d6c0f75048" class=""><details open=""><summary>Introduction to Practical Data Science</summary></details></h3><div class="indented"><p id="8601a86d-bd91-48c6-af45-52909b9259ff" class="">AI ML DL and DS</p><ul id="1267c303-b1d9-4f95-8859-09a2fe344c7e" class="bulleted-list"><li style="list-style-type:disc"><strong>AI</strong> :  is generally described as a technique that lets machines mimic human behavior.</li></ul><ul id="dc4547d6-cec6-4e30-ae19-46bf58797b93" class="bulleted-list"><li style="list-style-type:disc"><strong>ML</strong>: s a subset of AI that uses statistical methods and algorithms that are able to learn from data without being explicitly programmed</li></ul><ul id="303a609a-4b89-430d-b74f-89ded0d819b0" class="bulleted-list"><li style="list-style-type:disc"><strong>DL: </strong>yet another subset of machine learning, that uses artificial neural networks to learn from data.</li></ul><ul id="d53f4f13-1eaa-48b0-886b-afa9525da580" class="bulleted-list"><li style="list-style-type:disc"><strong>data Science</strong>: ruly is an interdisciplinary field that combines business and domain knowledge with mathematics, statistics, data visualization, and programming skills<figure id="c507003f-a1d5-4a18-9a5c-0091ae0c66d6" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled.png"><img style="width:1238px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled.png"/></a></figure><p id="1e8e0223-edf4-46b2-89b2-6f08ec120ac8" class=""><strong>Practical DS: </strong>gaining insigth for large datasets, the advantage of working on the cloud is getting bigger resources when needed</p><p id="699b6f1f-a209-4d58-90e6-95c60c163462" class=""><strong>Running DS projects in the cloud </strong>it allows more scability and freedmom , models turn more scalable. also you can store any amounts of data <div class="indented"><p id="2ff62040-5db2-4f0b-8621-02dcf4af163f" class="">Scaling up: bigger CPU</p><p id="6c89fd4d-f4fc-48b1-a6f2-07b590aa9b12" class="">Scaling out: multiple machines simultaneously (computaçaõ distribuida)</p><p id="1127d04a-a426-412f-898b-a9260bd308bd" class="">
</p></div></p></li></ul></div><p id="45396d3b-9da7-408d-bb9f-ddcbd5fad43c" class="">
</p><h3 id="7ee4de08-46f8-4705-b4f9-7889895e397d" class=""><details open=""><summary>Use case and data set</summary></details></h3><div class="indented"><figure id="9d08025c-6e72-40ba-9cdc-d3c33040ff8e" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%201.png"><img style="width:1844px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%201.png"/></a></figure><p id="0a181142-0f1b-4522-bdcc-3ef748349d6f" class="">Computer Vision also includes image classification</p><p id="15af4263-2234-4637-8df4-dadd06df69da" class="">NLP - Natural Language Processing</p><p id="1d61b4fc-3646-4edb-ac3a-b128bb08f8ef" class="">NLU - Natural Language Understaing</p><p id="b78df830-135c-4324-b29f-f3ac71400c70" class=""><strong>Task of the course: </strong>our task is to build an NLP model that will take those product reviews as input. You will then use the model to classify the sentiment of the reviews into the three classes of positive, neutral and negative. For example, a review such as I simply Love It, should be classified into the positive class. Multi-class classification is a supervised learning task hence you need to provide your tax classifier model with examples how to correctly learn to classify the products and the product reviews into the right sentiment classes.</p><figure id="1925f7ed-7342-47bf-b26e-883b1e7386ce" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%202.png"><img style="width:904px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%202.png"/></a></figure></div><h3 id="2778e549-45df-4356-bed2-f440b53119e5" class=""><details open=""><summary>Working with Data</summary></details></h3><div class="indented"><p id="68ce820a-1a52-411b-8362-426ee009e4f2" class="">Cloud DL allow you to using any kind of data:<div class="indented"><ul id="c8a1d47f-b2e0-4992-b64d-3dd0f34838aa" class="bulleted-list"><li style="list-style-type:disc">structure data</li></ul><ul id="6d6bd36c-a419-4b7f-aeaa-bda638160631" class="bulleted-list"><li style="list-style-type:disc">semi-structured: jason....</li></ul><ul id="5696865b-c6a5-4a07-87ab-d35a60ad25de" class="bulleted-list"><li style="list-style-type:disc"> unstructure: images , audio etc</li></ul><ul id="85cd20ae-ca87-4bfc-8ec8-7189b2b328cf" class="bulleted-list"><li style="list-style-type:disc">streaming data</li></ul><p id="b683392f-dd2a-4256-86b2-899e61471af3" class="">
</p></div></p><p id="009f227f-1efa-428e-ad20-449bb37621f2" class=""><mark class="highlight-orange_background"><strong>Amazon simple Storage Service - S3: </strong></mark></p><p id="e178b37d-226b-4f65-b0dd-5a600e8156f8" class=""><strong>File storage </strong>stores and manages data as individual files organized in hierarchical file folder structures. In contrast, <strong>block storage</strong> stores and manages data as individual chunks called the blocks. Each block receives a unique identifier, but no additional metadata is stored with that block. With object storage, data is stored and managed as objects, which consists of the data itself, any relevant metadata, such as when the object was last modified and a unique identifier. <strong>Object</strong> <strong>storage</strong> is particularly helpful for storing and retrieving growing amounts of data of any type hence it&#x27;s the perfect foundation for data lakes. <strong>Amazon S3 gives you access to durable and high available object storage in the cloud.</strong></p><p id="e2fd5506-bf71-4125-b18e-781e1bbc52de" class="">
</p><p id="c9c0998d-ba17-4e97-9f89-d2d80088e16a" class=""><mark class="highlight-orange_background"><strong>AWS Data Wrangler </strong></mark></p><p id="930beec8-2fc0-4ca3-aa0f-50f07de0fb54" class="">Now, let me introduce some additional toolbox items you will be working on this week. One of them is AWS Data Wrangler. AWS Data Wrangler is an open source Python library developed by members of the AWS professional services team. The library connects Pandas DataFrame with AWS data-related Services. Pandas is a very popular Python data analysis and manipulation tool. AWS Data Wrangler offers abstracted functions to load or unload data from data lakes, data warehouses or databases on AWS. You can install the library through the PIP install AWS wrangler command. Here&#x27;s a sample code snippet that shows how you can work with AWS Data Wrangler.<div class="indented"><figure id="d331cc31-789e-4a71-a688-baa3ed7e1847" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%203.png"><img style="width:1758px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%203.png"/></a></figure></div></p><p id="cb420752-cc47-4ab8-99f5-0efd5b0b2865" class=""><strong><mark class="highlight-orange_background">AWS Glue Data Catalog</mark></strong><div class="indented"><p id="0a98a912-cf53-4430-a257-250c20413d5d" class="">used to catalog the data in S3 data lake/bucket</p><p id="73dced39-8506-449b-844a-b7dd86ab559e" class="">just used for metadata, </p><figure id="c97d8bfb-7d03-4112-b39e-e120f132f855" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%204.png"><img style="width:1820px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%204.png"/></a></figure></div></p><p id="0f77457d-3973-49ff-aea5-2083945bc212" class="">
</p><p id="8e5a6f48-2def-4b5b-8425-90c5bb0b7bec" class=""><mark class="highlight-orange_background"><strong>AWS Athena </strong></mark><div class="indented"><p id="0145f26e-7111-4500-9ed7-ea7e79148791" class="">The data resides in S3, all you store in Wrangler is the metadata , </p><p id="b0b5d573-1101-40c9-a1da-99952992e5a9" class="">From the Python environment you&#x27;re working in, just use the Data Wrangler, Athena, read_SQL_query function. Pass in the SQL statement you have written and point to the AWS Glue database which contains the table you&#x27;ll reference here in the SQL query. Again, this database and table only contains the metadata of your data. The data still resides in S3, and when you run this Python command, AWS Data Wrangler will send this SQL query to Amazon Athena. Athena then runs the query on the specified dataset and stores the results in S3, and it also returns the results in a Pandas DataFrame as specified in the command shown here.</p><p id="511901d4-e295-471a-af49-18e60a5f0e93" class=""><strong>athena automatically scales out, using parallel computing for getting the data if needed</strong></p><figure id="6fc6b39e-03f3-41d6-8774-87f8a732c3c3" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%205.png"><img style="width:1708px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%205.png"/></a></figure><p id="83b3864b-fe2c-4a2e-b6bd-aab8ce6ac6df" class="">
</p><p id="61e81af0-eead-483c-86f0-458a88d3155d" class="">
</p></div></p></div><p id="20edc37a-3358-4aa9-bd33-04cd157f54c9" class="">
</p><h3 id="28302fe5-df5d-4acf-a8c1-6729784e18f1" class="">Reading Material</h3><p id="6dadfa2d-bbc4-4136-b3e6-ee17d8fab81c" class=""><a href="https://github.com/awslabs/aws-data-wrangler">AWS Data Wrangler</a></p><p id="3cef8c3a-d31b-43de-91be-d492f9a0d9d7" class=""><a href="https://aws.amazon.com/glue">AWS Glue</a></p><p id="c3e5388b-f097-41dd-a892-19540151aac8" class=""><a href="https://aws.amazon.com/athena/">Amazon Athena</a></p><p id="3c870f65-3412-421d-b258-aae3f15192e7" class=""><a href="https://matplotlib.org/">Matplotlib</a></p><p id="c014f761-43c4-4aa9-a277-efa8a5d8f9cf" class=""><a href="https://seaborn.pydata.org/">Seaborn</a></p><p id="20235444-85b1-40d8-80b7-74dd4a3edf17" class=""><a href="https://pandas.pydata.org/">Pandas</a></p><p id="02042be8-e474-4295-bb48-52d12740e50f" class=""><a href="https://numpy.org/">Numpy</a></p><p id="61a0dafc-c3e3-40b2-84ab-87902af03690" class="">
</p><p id="868a8992-7cd3-4eda-a1f5-5d37dffed6ea" class="">
</p><h2 id="566b71fd-c832-4abf-970e-ce0ff4ac5e6a" class="block-color-orange_background">W2 - Data Bias and Feature Importance</h2><p id="98c2b4aa-9472-4220-b089-9e5b8e2c2b3d" class="">
</p><h3 id="7c3e1360-62c7-458b-a020-b3c8f23c371e" class="">Statiscal Bias:</h3><ul id="82eacf8e-f754-450d-bc70-202016dac2e3" class="bulleted-list"><li style="list-style-type:disc">data is not representative</li></ul><ul id="f7c62517-95cd-400e-91e0-01faddc97aeb" class="bulleted-list"><li style="list-style-type:disc">imbalaced dataset</li></ul><p id="4e5cf05d-590e-4e74-9190-f9af19c571d1" class="">
</p><h3 id="cc0d31be-5126-4464-8a8b-3226771aa748" class="">Causes:</h3><ul id="63bea5af-c815-4928-af31-799aeae25c84" class="bulleted-list"><li style="list-style-type:disc">Activity bias (social media content): the population in social media does not represent the entire population</li></ul><ul id="5d6cab6d-9c61-4b67-9e3b-1268913b788b" class="bulleted-list"><li style="list-style-type:disc">societal bias (human generated bias): Data generated by humans can be biased because all of us have unconscious bias.</li></ul><ul id="776d9e6f-9156-49e4-85e0-33668798ab3f" class="bulleted-list"><li style="list-style-type:disc">Selection Bias: feedback loop, better recomendations will be more presented and therefore being more viewd and so on</li></ul><ul id="e4401d13-010b-4160-8333-d0972705190f" class="bulleted-list"><li style="list-style-type:disc">Data drift: data starts to drift/shift from the training data<ul id="c4ac1342-31be-4934-8af7-3538c2da5f4e" class="bulleted-list"><li style="list-style-type:circle">Covariante drift: the distribution of the independent variables or the features that make up your dataset can change</li></ul><ul id="576a97ee-4eee-4a9f-bd49-8f07634c4d53" class="bulleted-list"><li style="list-style-type:circle">Piror prob drift: data distribution of your labels or the targeted variables might change</li></ul><ul id="9e99201b-75ab-474c-bec7-f37f2fb2b63b" class="bulleted-list"><li style="list-style-type:circle">concept drif: defination on levels might change, the relationship between the two, that is the relationship between the features and the labels can change as well.</li></ul></li></ul><p id="56baa432-a245-4359-b850-86efdb213639" class="">
</p><h3 id="5a39cd2b-336f-4b3a-80b3-ba89acfe2b71" class="">Measure bias</h3><ul id="744fe0b2-a322-4e71-b99c-4f5546d71662" class="bulleted-list"><li style="list-style-type:disc">Class imbalance (measures the imbalance in the number of examples that are provided for different facet values in your dataset</li></ul><ul id="f2d7b319-114b-4598-b8de-185e41d1e8cd" class="bulleted-list"><li style="list-style-type:disc">DPL: is actually looking for higher ratings than any other product categories.</li></ul><p id="f29bfe16-8e62-4d2f-aa95-9ce5c9378106" class="">
</p><h3 id="26ef5f4e-5e55-4fe1-9455-b22a5271fd00" class=""><details open=""><summary><strong>SageMaker Data Wrangler:</strong></summary></details></h3><div class="indented"><figure id="8fdc782f-6d90-4cef-bc2e-ffec236844f7" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%206.png"><img style="width:1570px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%206.png"/></a></figure><p id="12bea0e3-8708-4f9e-9b65-cec046694104" class="">it allows to generate Bias reports on the datasets, it also peforms this reports on deployed models </p><p id="85dd37ea-c7ec-4998-ba1c-6c2b747d8ce7" class="">It only used a sample of the data to perform the analisys</p><p id="603ea753-7301-489c-b51e-9b8ade0d265d" class="">
</p></div><p id="668d0453-f9ff-4696-b2c7-8dda95ac1841" class="">
</p><h3 id="6f8c2c07-8b9c-42d8-85a6-014bcd252b51" class=""><details open=""><summary><strong>SageMaker Clarify Processor </strong></summary></details></h3><div class="indented"><p id="0fb26217-cbc3-4efa-a085-dd3dc6b8fa27" class="">is a construct that allows you to scale the bias detection process into a distributed cluster.</p><figure id="3f71ebbc-68c6-48df-b824-c054c602bf8a" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%207.png"><img style="width:1510px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%207.png"/></a></figure><p id="c61dded1-7060-491e-9ac6-c86da0add9d8" class="">
</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="d5c68659-d832-4ae2-826e-ad6b75772aa0"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%"><strong>Instant count represents the number of nodes that are included in the cluster, and instance type represents the processing capacity of each individual node in the cluster.</strong></div></figure><p id="012f304e-5cc6-467c-b1f5-8d88054d0ca3" class="">You need to specify the 3 objects before running the pre trained model to detect the bias. You can select <strong>different measures: </strong>class imbalance or DPL</p><p id="da8c5087-5e5c-4dd6-b3e9-148aa5336995" class="">SageMaker Clarify is using a construct called <strong>SageMaker Processing Job</strong> to execute the bias detection at scale (scale-out). SageMaker Processing Jobs is a construct that allows you to perform any data-related tasks at scale</p><p id="8ae13616-c1bd-4e2d-b826-bdef285f2389" class="">the SageMaker Processing Job expects the data to be in an S3 bucket.</p><p id="32c62e1f-1e14-4a59-8b71-a465a7a90e71" class="">the report generated is stored in the S3 bucket</p><p id="a161d387-c40c-4e8e-b73e-486b67fc1b22" class="">
</p></div><p id="6d8d7512-ccd7-4c0a-acaa-76f8ecbefaf5" class="">
</p><h3 id="c58b98ea-5ed4-4360-9fc5-0d48649f4f4a" class=""><strong>SM Data Wrangler vs SM Clarify</strong></h3><p id="81d0fa8d-f19d-43f8-b153-27c30032cfd9" class="">You learned about two tools to detect statistical bias in your data sets. SageMaker Data Wrangler and SageMaker Clarify. Now the question becomes, which one of these tools should you use, in which situation? The first option, Data Wrangler, provides you with more of a UI based visual experience. So, if you would like to connect to multiple data sources and explore your data in more visual format and configure what goes into your bias reports by making selections from drop down boxes and option buttons. And finally, launch the bias detection job using a button click, Data Wrangler is the tool for you. Keep in mind that Data Wrangler is only using a subset of your data to detect bias in that data set. On the other hand, SageMaker Clarify provides you with more of an API based approach. Additionally, Clarify also provides you with the ability to scale out the bias detection process. SageMaker Clarify uses a construct called processing jobs that allow you to configure a distributed cluster to execute your bias detection job at scale. So, if you&#x27;re thinking of large volumes of data, for example, millions of millions of rows of product reviews and you want to explore that data set for bias. Then, SageMaker Clarify is the tool for you, so that you can take advantage of the scale and capacity offered by Cloud.</p><p id="97c2cf3a-b9b8-48d3-ba31-b086d58b34bd" class="">
</p><h3 id="af4b1edb-2a52-4ff7-b382-9612bf2d3c82" class=""><details open=""><summary>SHAP → shapley additive explanations</summary></details></h3><div class="indented"><p id="43916ce2-cc51-4b6b-89bf-294d7eddd8d8" class="">Feature importance</p><p id="e864cee8-449e-41a2-bf8e-f29738feca83" class="">based on shapey values theory</p></div><p id="e3a91c6a-9738-45db-a2c4-dbf07bed01ea" class="">
</p><h3 id="5c945db4-d9bd-4d34-af95-a6f608259e22" class="">Reading Material</h3><p id="1704045d-d30d-4f5e-a5e6-3dc80a88648b" class=""><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html">Measure Pretraining Bias - Amazon SageMaker</a></p><p id="0248358e-fb37-458d-8617-799e18a8fade" class=""><a href="https://shap.readthedocs.io/en/latest/">SHAP</a></p><p id="4e076e37-f0a1-4d3f-ae38-99ae8cd9584b" class=""><a href="https://aws.amazon.com/sagemaker/pricing/">https://aws.amazon.com/sagemaker/pricing/</a></p><p id="da344022-0de7-4e02-b2bb-dd7c28c615ed" class="">
</p><h2 id="9f91eaa2-e253-4ea4-9c39-87f51b5647ab" class="block-color-orange_background">W3 - Automated Machine Learning (AutoML)</h2><p id="1d1e666a-d0fc-4c11-844f-467de1177926" class="">Tool: SagemakerAutopilot</p><p id="6fd2c8e0-4915-4e14-bc01-3652db88bb9c" class="">
</p><p id="035bd8ca-e13e-4f29-85f8-f4c05cfa2062" class=""><mark class="highlight-orange_background"><strong>AutoML</strong></mark> → allows to reduce time, iterate quickly, allows to tune models in parrallell when used with could computing and </p><p id="02a16ef7-7c45-42c6-8638-c7bfc3ddddda" class="">
</p><h3 id="7fbbcb76-2037-43af-ad6c-c63472da7960" class="">AutoML Flow</h3><p id="de806cb3-05e0-44ae-8154-b5a649cc8eb7" class="">Basic steps of Data preparation flow: ingest, feature enngeneering, train-validation split etc etc etc</p><p id="d811a531-2b0b-4f24-aa3f-e56b3d37f131" class="">Auto ML uses Ml to automate some ML steps:</p><figure id="d5012089-535e-4abb-bd80-ed828a382bc1" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%208.png"><img style="width:1760px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%208.png"/></a></figure><p id="ae32e554-6896-4e64-ba2c-818db333210a" class="">autoML it receives data and does analysis to understand which Ml problem it’s facing: classification, multi-classification or regression. Experiments different algorithms, transforms data /data engineer, train with different hyper-parameters</p><p id="dd385e96-1376-4b99-b885-223c6afb11e4" class="">As a reminder, <strong>AutoML</strong> is a capability that applies machine learning and Automation to model-building task by automatically analyzing your data, automatically selecting the right algorithm or algorithms for your experiments, automatically preparing and applying data transformations, and then finally, automatically training and tuning your model through a number of iterations, until the most performant model is identified</p><h3 id="5e7dd871-ddd6-4c09-85c6-7f257f9e46e5" class="">Sagemaker Autopilot</h3><p id="1cc13d4f-ac8b-4156-8d3a-43d9d000c965" class="">auto pilot generates all the code in jupyter notebooks that allows you to reproduce all the steps, is fully transparent</p><p id="c8fcfe32-4b23-4c6e-a91f-7bd320742897" class="">when creating autopilot experiment you must say which variable is the target, it works for regression, binary classification and multi class</p><p id="6c0a61f2-8a62-4ed8-bb95-e8f8bb2f9a9e" class="">it creates two types of notebooks:</p><ul id="25c19511-4acd-4b35-b50e-1cd92a0903b7" class="bulleted-list"><li style="list-style-type:disc">data exploration notebook, identifies potential issues in the data</li></ul><ul id="604a30cd-7cf5-4d3f-9737-34d4fd8658db" class="bulleted-list"><li style="list-style-type:disc">candidate generated notebook: contains each suggested data pre-processing step. The algorithm and the hyper-parameter ranges that will be used for the tuning job</li></ul><p id="6e77481f-ed94-4d09-b07b-53c4f7423434" class="">It allows you to choose which metric to use to evaluate the model and allows to tune how much of “auto” it is, you can select some steps to perform manually. </p><p id="702764cf-f3a1-42e8-91dc-8dbe994a8d64" class="">
</p><p id="13356f2f-ca52-4f16-a5be-2c563993f221" class="">experience = job</p><p id="c43ef492-242e-4107-b515-194ce300b240" class="">
</p><p id="633c4f1c-f308-4bb5-abb4-f3b9898712f8" class="">Interact with AutoPilot:</p><figure id="c3861623-0a78-4fb0-acc0-058e00e4fd6d" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%209.png"><img style="width:1444px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%209.png"/></a></figure><p id="7fdd9a29-ccdd-4dd6-8e26-33d222dbefab" class="">
</p><p id="f23277ee-d484-499c-a0ef-51e5e95215dc" class="">Programatically:<div class="indented"><p id="d65ff8d0-fb1c-4fd3-aa5e-2a1bac1642d2" class="">Among other specifications that you can configure:</p><figure id="037ec82a-5f7b-4974-a41e-78f1e7bdfff2" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%2010.png"><img style="width:1394px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%2010.png"/></a></figure></div></p><p id="acc870c6-aaa9-4765-9d7a-52cc8e4c2e84" class="">
</p><h3 id="3b3ddd66-5b93-4807-85a2-1dcaec328e99" class="">SM Autopilot outputs:</h3><p id="a6f3006d-a095-4282-b1b4-b270d8a260d9" class="">are stored in S3 bucket specified in the config , also accessible through the SM studio</p><figure id="6019bf10-4fc3-4fef-ad4a-6eab6b2b0057" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%2011.png"><img style="width:1784px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%2011.png"/></a></figure><p id="37827edd-572c-4a40-908b-0cea697db56c" class="">
</p><h3 id="973db3bf-6806-4abe-b0eb-9c96a4becf73" class="">Model Deploy</h3><p id="0e435a9f-ea28-4c06-bc15-0ae590f4a3a0" class="">Sagemaker are supports both <strong>batch</strong> and <strong>real</strong> <strong>time</strong> <strong>deployments</strong>. In this case, you need the model to be persistently available to be able to serve real time request for prediction. Serving your predictions in real time requires a model serving stack that not only has your trained model but also a hosting stack to be able to serve those predictions. In this typically involves some type of a proxy, a web server that can interact with your loaded serving code and you&#x27;re trained model. Your model can then be consumed by client applications through real time, invoke employment API requests with Sagemaker model hosting, you simply choose the instance type as well as the count combined with the doctor container image that you want to use for inference and then Sagemaker takes care of creating the endpoint. In deploying that model to the endpoint, you can also configure automatic scaling to scale your endpoint to meet the demands of your workload by taking advantage of on demand capacity when it&#x27;s needed.</p><p id="9644d2bc-208b-4021-8ed8-82d398b057c5" class="">When you choose to deploy a candidate pipeline generated by autopilot, it gets deployed using a Sagemaker hosting feature called inference pipeline. </p><p id="b7ede544-72e8-4b89-94e9-4ef85730d310" class=""><strong>Deploy inference pipeline </strong>contains 3 containers:</p><ul id="602fd006-c406-4fbd-9ad6-081eeb352473" class="bulleted-list"><li style="list-style-type:disc"><strong>Data Transformation Container: </strong>his container will perform the same transformations on your data set that were used for training so that you can ensure your prediction request data is in the correct format for inference</li></ul><ul id="0f8f428f-4ba9-4bab-91e7-f3ad67aaea90" class="bulleted-list"><li style="list-style-type:disc"><strong>Algorithm</strong> <strong>Container</strong>: his is the container that contains the train model artifact that was selected as the best performing model based on your hyper parameter tuning jobs</li></ul><ul id="0c40de29-af19-4ea2-8a83-4f3df439e8a4" class="bulleted-list"><li style="list-style-type:disc"><strong>Inverse</strong> <strong>Label</strong> <strong>Container</strong>: used to post process your prediction into a readable value by your application that consumes the output</li></ul><p id="9afbf481-238c-4cd4-bd1e-6c4ce0c02e50" class="">With inference pipeline, you&#x27;re able to host your data transformation model, your product classification model and your inverse label transformer behind the same endpoint. This allows you to keep your training and inference code in sync and allows you to abstract those transformations away from your consuming applications. When an inference request comes in, the request is sent to the first data transformation model and then the remaining models are sequentially run with that final model. In this case, the inverse label transformer sending the final influence result back to your client application. In this section, I briefly covered model hosting on Sagemaker, specifically focusing on real time persistent endpoints and the ability for you to deploy the candidate pipeline model generated by autopilot with a simple configuration. This allows you to host your model using Sagemaker managed endpoints, managed endpoints mean you don&#x27;t have to manage the underlying infrastructure that&#x27;s hosting your model and you can focus on machine learning.</p><h3 id="a5882644-baab-4405-a280-f6b739d8f11c" class="">Reading material:</h3><p id="3bf53dc7-0fe7-475c-8d8c-2a71cb31a83b" class=""><a href="https://aws.amazon.com/sagemaker/autopilot/">Amazon SageMaker Autopilot</a></p><p id="5250f2ea-f380-4f29-b30a-a97cfb5b63ea" class="">
</p><h2 id="ed038e8e-89a8-4673-8d92-a3b5fe8bc6e4" class="block-color-orange_background">W<strong>4 - Built-in Algorithms</strong></h2><p id="8b132eef-c3de-42c5-9fdc-ec806320d5b7" class="">
</p><p id="c3f94b90-be66-46da-9c39-efc0050ba8fe" class=""><strong>Built-in algorithms: </strong>built-in algorithms to train and deploy your models help you to run experiments quickly because you don&#x27;t need to write any custom model code</p><p id="c8fba55d-d933-470f-9ee9-5ec88efb4336" class="">
</p><p id="31e507ab-f2be-4309-a090-9f40c33d8cef" class=""><mark class="highlight-orange_background"><strong>Advantages</strong></mark><strong>:</strong></p><ul id="75510f7a-f1fc-4ae8-8c4a-a967bc1bb697" class="bulleted-list"><li style="list-style-type:disc">really scalable, you can swich fom CPU to GPU by simpling change the instance type and also allow parallell computing just by increasing the instance count</li></ul><ul id="60b0d698-b9a5-4a42-acc5-71ab3644a95f" class="bulleted-list"><li style="list-style-type:disc">allows to save time ( easier to implement)</li></ul><ul id="59cf7c44-dfa3-409a-bb14-3c30bc0d4f69" class="bulleted-list"><li style="list-style-type:disc">allows to download train models and use them elsewhere</li></ul><p id="1973b1f0-c0fc-4477-a299-480334657570" class=""><mark class="highlight-orange_background"><strong>When to use:</strong></mark></p><ul id="02b4302a-3cf3-40e5-baea-748c6eea891b" class="bulleted-list"><li style="list-style-type:disc"><strong>Built in Algorithms:</strong><em> </em>if the bult-in can solve the task why not use it? keep it simple</li></ul><ul id="01d20405-7d02-447b-9866-e4f60cc22ebf" class="bulleted-list"><li style="list-style-type:disc"><strong>Bring your own code:</strong> make some changes to built in algorithms</li></ul><ul id="339e848c-05e4-4e31-92fd-de332e91efc4" class="bulleted-list"><li style="list-style-type:disc"><strong>Bring your own Container</strong>: writing algorithms in docker containers.</li></ul><figure id="53b4c8fa-b9a7-4cdc-9c6c-f441d153c23c" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%2012.png"><img style="width:1615px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%2012.png"/></a></figure><p id="1634c187-d232-4246-b689-cdbcddd49a85" class=""><mark class="highlight-orange_background"><strong>Examples of built-in algorithms for each problem:</strong></mark></p><figure id="e8b4c5c2-73db-4a58-8f08-697cbf757914" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%2013.png"><img style="width:1562px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%2013.png"/></a></figure><p id="4ac84eba-8506-4fa9-ad72-f55be4f320a9" class=""><strong>Linear Learner:</strong> extends up on typical linear models by actually training many models in parallel, each with slightly different type of parameters and then returns the one with the best fit</p><p id="41315d68-e740-47ee-a6dd-79cbd3ef6f81" class=""><strong>DeepAR Forecasting:</strong> is a supervised learning algorithm for forecasting scalar, meaning one-dimensional time series, using recurrent neural networks or RNNs</p><figure id="9b027d8e-bccd-42b4-953d-4b2793597718" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%2014.png"><img style="width:1574px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%2014.png"/></a></figure><p id="f9600217-d799-4e11-aa3a-8f9f94136db2" class=""><strong>RCF:</strong> is an unsupervised algorithm for detecting anomalous data points within a dataset. RCF associates an anomaly score with each data point. Low score values indicate that the data point is considered normal. However, high values indicate the presence often anomaly in the data</p><p id="66a14e72-f666-4426-af14-e92477e29aa8" class=""><strong>LDA:</strong> is a generative probability model, which means it attempts to provide a model for the distribution of outputs and inputs based on latent variables. In statistics, latent variables are variables that are not directly observed, but are inferred from other variables in the training dataset. This is opposed to the discriminative models, which attempt to learn how inputs map to the outputs.</p><p id="43d09816-1833-4d18-8be3-8f14b717e897" class=""><strong>NTM:</strong> uses a deep learning model rather than a pure statistical model</p><figure id="425297c9-a553-4ffb-b383-60a9d65facc2" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%2015.png"><img style="width:1571px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%2015.png"/></a></figure><p id="e5f3ca1e-2930-4084-bc02-27efa2dba884" class=""><strong>image classification: </strong>algorithm can be run in two modes; full training or transfer learning. In full training, the network is initialized with random weights and trained on user data from scratch. In transfer learning mode, network is initialized with pre-trained weights, and just the top fully connected layer is initialized with the random weights. Then the whole network is fine tuned with new data. In this mode, training can be achieved even with a smaller dataset. This is because the network is already trained and therefore can be used in cases without sufficient training data</p><p id="f77ba04d-7ea4-43b5-b090-18fca45335b5" class=""><strong>object detection algorithm</strong> detects all instances of predefined objects within the images categorized as the object, and also adds a bounding box indicating the location and scale of the object in given images.</p><p id="c2216a69-7d41-441d-8fbf-a9b6fccddd88" class=""><strong>Semantic segmentation </strong>is different from the image classification and object detection in that it classifies every pixel in an image. This leads to information about the shapes of the objects contained in the image. The segmentation output is represented as a grayscale image called a segmentation mask that has the same shape as the input image. Classifying each pixel is fundamental for understanding scenes, which is critical to an increasing number of Compute Edition applications, such as self-driving vehicles, but also medical imaging diagnostics, and robot sensing</p><figure id="cd893164-d4a3-41db-a6aa-551f11be795d" class="image"><a href="C1%20%E2%86%92%20Analy%20c5070/Untitled%2016.png"><img style="width:1576px" src="C1%20%E2%86%92%20Analy%20c5070/Untitled%2016.png"/></a></figure><p id="b94a2151-a03d-4265-a85a-0baaeda572b3" class=""><strong>sequence to sequence algorithm</strong> is a supervised learning algorithm where the input is a sequence of tokens, for example, text or audio, and the output is generated as another sequence of tokens</p><p id="a1d45c84-188d-40e5-937a-0f24b3e7d944" class=""><strong>blazing text: </strong>optimized implementations of the Word2Vec and text classification algorithms; Bazing text creates character and graham and embeddings using the continuous bag of words and skip gram training architectures, blazing text also allows you to save money by stopping your model training early.</p><p id="82745dfe-1f14-4738-a95f-aed651478390" class="">
</p><h3 id="cd8bfade-2443-416f-b3eb-99c557892e72" class="">Reading Material</h3><p id="736d5839-811c-42aa-8612-007bbdeb07e1" class=""><a href="https://arxiv.org/pdf/1301.3781.pdf">Word2Vec algorithm</a></p><p id="2ca38aea-8572-4435-a91b-587b29e8f830" class=""><a href="https://www.aclweb.org/anthology/D14-1162.pdf">GloVe algorithm</a></p><p id="a055ffb2-226c-46ba-be5e-ff61c9bb0f91" class=""><a href="https://arxiv.org/pdf/1607.04606v2.pdf">FastText algorithm</a></p><p id="24ea03a2-1e0f-44e6-b2f2-106ac1c026ef" class=""><a href="https://arxiv.org/abs/1706.03762">Transformer architecture, &quot;Attention Is All You Need&quot;</a></p><p id="1cb219a0-3de8-4de4-95bc-e16ca608a0ff" class=""><a href="https://dl.acm.org/doi/pdf/10.1145/3146347.3146354">BlazingText algorithm</a></p><p id="60fffeea-8ea9-4639-8041-a8b903fe9b2a" class=""><a href="https://arxiv.org/pdf/1802.05365v2.pdf">ELMo algorithm</a></p><p id="ca1418c1-d857-4ce8-a17c-acc5a1e9bdcd" class=""><a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT model architecture</a></p><p id="2efeef9e-af02-4038-90ed-053f43fd7a40" class=""><a href="https://arxiv.org/abs/1810.04805">BERT model architecture</a></p><p id="2b78d646-8281-488a-a301-11c15c6ee429" class=""><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html">Built-in algorithms</a></p><p id="44415c8d-c869-4854-814c-25dd66621f29" class=""><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html">Amazon SageMaker BlazingText</a></p><p id="e7dde069-e93b-4298-8ea3-aa782659aa7d" class="">
</p></div></article></body></html>